{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-29T14:31:53.695334Z",
     "start_time": "2023-08-29T14:31:53.686002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Kafka Consumer creation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29bed481de2fbba8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer(os.environ.get('KAFKA_TOPIC_NAME'), bootstrap_servers=['18.119.159.115:9092'], value_deserializer=lambda x: json.loads(x.decode('utf-8')))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T14:31:54.178332Z",
     "start_time": "2023-08-29T14:31:53.693123Z"
    }
   },
   "id": "b829f0929d94278"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# S3 Client creation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "506035d84580544f"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\n",
    "    's3', \n",
    "    aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "    aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY'),\n",
    "    region_name=os.environ.get('AWS_REGION')\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T14:31:54.262630Z",
     "start_time": "2023-08-29T14:31:54.177520Z"
    }
   },
   "id": "1a1a592f78544746"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Receives market data from producer and uploads it to S3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ccadcd7a12d3eb3"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object stock_market_data/AAPL_stock_market_0.json uploaded successfully to S3.\n",
      "Object stock_market_data/AAPL_stock_market_1.json uploaded successfully to S3.\n",
      "Object stock_market_data/AAPL_stock_market_2.json uploaded successfully to S3.\n",
      "Object stock_market_data/AAPL_stock_market_3.json uploaded successfully to S3.\n",
      "Object stock_market_data/AAPL_stock_market_4.json uploaded successfully to S3.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# iterate over the consumer\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m count, message \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(consumer):\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m      4\u001B[0m         \u001B[38;5;66;03m# create the key to be used in S3\u001B[39;00m\n\u001B[1;32m      5\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstock_market_data/AAPL_stock_market_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcount\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.json\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/Documents/Python/python_kafka_project/venv/lib/python3.11/site-packages/kafka/consumer/group.py:1193\u001B[0m, in \u001B[0;36mKafkaConsumer.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1191\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnext_v1()\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1193\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext_v2\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Python/python_kafka_project/venv/lib/python3.11/site-packages/kafka/consumer/group.py:1201\u001B[0m, in \u001B[0;36mKafkaConsumer.next_v2\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message_generator_v2()\n\u001B[1;32m   1200\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1201\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator)\n\u001B[1;32m   1202\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m   1203\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Python/python_kafka_project/venv/lib/python3.11/site-packages/kafka/consumer/group.py:1116\u001B[0m, in \u001B[0;36mKafkaConsumer._message_generator_v2\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_message_generator_v2\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   1115\u001B[0m     timeout_ms \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1000\u001B[39m \u001B[38;5;241m*\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_consumer_timeout \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mtime())\n\u001B[0;32m-> 1116\u001B[0m     record_map \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout_ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupdate_offsets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   1117\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m tp, records \u001B[38;5;129;01min\u001B[39;00m six\u001B[38;5;241m.\u001B[39miteritems(record_map):\n\u001B[1;32m   1118\u001B[0m         \u001B[38;5;66;03m# Generators are stateful, and it is possible that the tp / records\u001B[39;00m\n\u001B[1;32m   1119\u001B[0m         \u001B[38;5;66;03m# here may become stale during iteration -- i.e., we seek to a\u001B[39;00m\n\u001B[1;32m   1120\u001B[0m         \u001B[38;5;66;03m# different offset, pause consumption, or lose assignment.\u001B[39;00m\n\u001B[1;32m   1121\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m records:\n\u001B[1;32m   1122\u001B[0m             \u001B[38;5;66;03m# is_fetchable(tp) should handle assignment changes and offset\u001B[39;00m\n\u001B[1;32m   1123\u001B[0m             \u001B[38;5;66;03m# resets; for all other changes (e.g., seeks) we'll rely on the\u001B[39;00m\n\u001B[1;32m   1124\u001B[0m             \u001B[38;5;66;03m# outer function destroying the existing iterator/generator\u001B[39;00m\n\u001B[1;32m   1125\u001B[0m             \u001B[38;5;66;03m# via self._iterator = None\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Python/python_kafka_project/venv/lib/python3.11/site-packages/kafka/consumer/group.py:655\u001B[0m, in \u001B[0;36mKafkaConsumer.poll\u001B[0;34m(self, timeout_ms, max_records, update_offsets)\u001B[0m\n\u001B[1;32m    653\u001B[0m remaining \u001B[38;5;241m=\u001B[39m timeout_ms\n\u001B[1;32m    654\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 655\u001B[0m     records \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll_once\u001B[49m\u001B[43m(\u001B[49m\u001B[43mremaining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_records\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupdate_offsets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mupdate_offsets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    656\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m records:\n\u001B[1;32m    657\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m records\n",
      "File \u001B[0;32m~/Documents/Python/python_kafka_project/venv/lib/python3.11/site-packages/kafka/consumer/group.py:702\u001B[0m, in \u001B[0;36mKafkaConsumer._poll_once\u001B[0;34m(self, timeout_ms, max_records, update_offsets)\u001B[0m\n\u001B[1;32m    699\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39mpoll(timeout_ms\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    701\u001B[0m timeout_ms \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(timeout_ms, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_coordinator\u001B[38;5;241m.\u001B[39mtime_to_next_poll() \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m)\n\u001B[0;32m--> 702\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout_ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;66;03m# after the long poll, we should check whether the group needs to rebalance\u001B[39;00m\n\u001B[1;32m    704\u001B[0m \u001B[38;5;66;03m# prior to returning data so that the group can stabilize faster\u001B[39;00m\n\u001B[1;32m    705\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_coordinator\u001B[38;5;241m.\u001B[39mneed_rejoin():\n",
      "File \u001B[0;32m~/Documents/Python/python_kafka_project/venv/lib/python3.11/site-packages/kafka/client_async.py:602\u001B[0m, in \u001B[0;36mKafkaClient.poll\u001B[0;34m(self, timeout_ms, future)\u001B[0m\n\u001B[1;32m    599\u001B[0m             timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(timeout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mretry_backoff_ms\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m    600\u001B[0m         timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m0\u001B[39m, timeout)  \u001B[38;5;66;03m# avoid negative timeouts\u001B[39;00m\n\u001B[0;32m--> 602\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    604\u001B[0m \u001B[38;5;66;03m# called without the lock to avoid deadlock potential\u001B[39;00m\n\u001B[1;32m    605\u001B[0m \u001B[38;5;66;03m# if handlers need to acquire locks\u001B[39;00m\n\u001B[1;32m    606\u001B[0m responses\u001B[38;5;241m.\u001B[39mextend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_pending_completed_requests())\n",
      "File \u001B[0;32m~/Documents/Python/python_kafka_project/venv/lib/python3.11/site-packages/kafka/client_async.py:634\u001B[0m, in \u001B[0;36mKafkaClient._poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_register_send_sockets()\n\u001B[1;32m    633\u001B[0m start_select \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m--> 634\u001B[0m ready \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    635\u001B[0m end_select \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    636\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sensors:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/selectors.py:561\u001B[0m, in \u001B[0;36mKqueueSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    559\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    560\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 561\u001B[0m     kev_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_selector\u001B[38;5;241m.\u001B[39mcontrol(\u001B[38;5;28;01mNone\u001B[39;00m, max_ev, timeout)\n\u001B[1;32m    562\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[1;32m    563\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# iterate over the consumer\n",
    "for count, message in enumerate(consumer):\n",
    "    try:\n",
    "        # create the key to be used in S3\n",
    "        key = f\"stock_market_data/AAPL_stock_market_{count}.json\"\n",
    "        # convert Python object into a JSON\n",
    "        json_data = json.dumps(message.value)\n",
    "        # upload the file to S3\n",
    "        s3_client.put_object(Bucket=os.environ.get('AWS_BUCKET_NAME'), Key=key, Body=json_data)\n",
    "        print(f\"Object {key} uploaded successfully to S3.\")\n",
    "    except NoCredentialsError as e:\n",
    "        print(f\"You don't have the neccessary credentials to upload the file.\\nException: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f'Something went wrong when trying to upload an object to S3.\\nException: {e}')\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T14:32:06.153294Z",
     "start_time": "2023-08-29T14:31:54.265278Z"
    }
   },
   "id": "bcfbb6498c8a85a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-29T14:32:06.149479Z"
    }
   },
   "id": "b4be2d6b746058a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
